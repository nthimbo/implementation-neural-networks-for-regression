# implementation-neural-networks-for-regression
In this project I try  to reconstruct in the region [0, 1]×[0, 1] the Franke’s function (see https://www.sfu.ca/~ssurjano/franke2d.html). The data set is obtained by sampling on 100 random points X the function and adding a uni- form noise, i.e. Y = f (X ) + ε 
This project was part of homeworks in Optimization methods for Data Science course at La Sapienza University of Rome. 
The project has 3 parts:
part01: (Full minimization) Consider a shallow Feedforward Neural Network (FNN) (one
only hidden layer) that provides the model f(x) using MLP
part02: We considered Radial Basis Function 
Part03: Two blocks Methods for Shallow MLP
